{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trgscott/LELA70502_Coursework/blob/main/Can_language_models_generate_more_original_ideas%3F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Can language models generate more original ideas?**"
      ],
      "metadata": {
        "id": "9ZY92k3vvICR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code tests whether fine-tuning GPT-2 on fictional content and adapting the decoding parameters can align a model to generate more original ideas. This is tested via self-METEOR and ROUGE-L for the semantic difference between generated texts and a set of baseline texts. Answers to brainteaser puzzles are also used to test the coherence and value of generated ideas.\n",
        "\n",
        "The temperature and K values will need to be varied manually and the generation and testing codes re-run if you would like to see the differences in the parameters."
      ],
      "metadata": {
        "id": "sTg7zbDuvRgt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smrpkMspRVG8"
      },
      "source": [
        "Source for book plots:\n",
        "\n",
        "https://www.cs.cmu.edu/~dbamman/booksummaries.html\n",
        "\n",
        "Source for ratings of books:\n",
        "\n",
        "https://cseweb.ucsd.edu/~jmcauley/datasets/goodreads.html\n",
        "\n",
        "Source for puzzles:\n",
        "\n",
        "https://huggingface.co/datasets/ErfanMoosaviMonazzah/brain-teasers\n",
        "\n",
        "Source for underlying training code framework:\n",
        "\n",
        "https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G1AuiGDufsl"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -U\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdBR2gABxP1i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import gzip\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from random import randint\n",
        "import evaluate\n",
        "import nltk\n",
        "from nltk.translate import meteor\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import WordNetCorpusReader, wordnet\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLSTE6Q6YXP6"
      },
      "outputs": [],
      "source": [
        "# Set the random seed value for reproducibility\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx2F7eFmEYvq"
      },
      "source": [
        "# **Importing book plots, ratings and puzzles into pandas dataframes:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOqqq8L0Ma6g"
      },
      "outputs": [],
      "source": [
        "#import plot summaries data\n",
        "!wget https://www.cs.cmu.edu/~dbamman/data/booksummaries.tar.gz\n",
        "!gunzip booksummaries.tar.gz\n",
        "!tar -xvf booksummaries.tar\n",
        "plots_df=pd.read_table(\"booksummaries/booksummaries.txt\", header=None, names=[\"Wikipedia_ID\", \"Freebase_ID\", \"title\", \"Author\", \"Publication_Date\", \"Book_Genres\", \"Plot_Summary\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up3czW4wEMal"
      },
      "outputs": [],
      "source": [
        "#plots_df.loc[:,[\"Plot_Summary\",\"title\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHuYJ6R7ZvGp"
      },
      "outputs": [],
      "source": [
        "#import book reviews data\n",
        "!wget https://mcauleylab.ucsd.edu/public_datasets/gdrive/goodreads/byGenre/goodreads_books_fantasy_paranormal.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1S_irgeiVn4"
      },
      "outputs": [],
      "source": [
        "reviews_df = pd.read_json('goodreads_books_fantasy_paranormal.json.gz', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwHhvGP3fjFl"
      },
      "outputs": [],
      "source": [
        "#reviews_df.loc[:,['title','average_rating']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtmrI0ZbVEEu"
      },
      "outputs": [],
      "source": [
        "#match set of titles in both plot summaries and goodreads reviews data\n",
        "plots_reviews = plots_df.merge(reviews_df[['title', 'average_rating']], 'left')\n",
        "#remove any that have no ratings\n",
        "plots_reviews = plots_reviews[plots_reviews['average_rating'].notnull()]\n",
        "#deduplicate based on Wikipedia IDs\n",
        "plots_reviews = plots_reviews.drop_duplicates(subset=['Wikipedia_ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8xrVAGHI2K1"
      },
      "outputs": [],
      "source": [
        "#filter to only 3.7+ rating\n",
        "plots_reviews['average_rating'] = pd.to_numeric(plots_reviews['average_rating'])\n",
        "plots_reviews = plots_reviews[plots_reviews.average_rating > 3.7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUV9cGeIImEL"
      },
      "outputs": [],
      "source": [
        "#only take the summaries\n",
        "plots_reviews = plots_reviews.Plot_Summary.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPI1GF6cnykg"
      },
      "outputs": [],
      "source": [
        "#shuffle the plot reviews\n",
        "random.shuffle(plots_reviews.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxcLb1gS4YdP"
      },
      "outputs": [],
      "source": [
        "#Convert back to series after shuffle as list, otherwise won't work for training\n",
        "plots_reviews = pd.Series(plots_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8Wg24ieskDi"
      },
      "outputs": [],
      "source": [
        "#plots_reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRsvE_IXpLCc"
      },
      "outputs": [],
      "source": [
        "#split the plot reviews into 90% training, 10% test\n",
        "plots_reviews_train, plots_reviews_test = train_test_split(plots_reviews, test_size=0.05, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7yrtpa5qqQF"
      },
      "outputs": [],
      "source": [
        "#print(len(plots_reviews_train))\n",
        "#print(len(plots_reviews_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezli9bxi0Jw4"
      },
      "outputs": [],
      "source": [
        "#Import the puzzles using recommended code\n",
        "splits = {'sp': 'data/sp-00000-of-00001.parquet', 'wp': 'data/wp-00000-of-00001.parquet'}\n",
        "puzzles = pd.read_parquet(\"hf://datasets/ErfanMoosaviMonazzah/brain-teasers/\" + splits[\"sp\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS9py73Bq6Gk"
      },
      "outputs": [],
      "source": [
        "#shuffle the puzzles\n",
        "puzzles = puzzles.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4WVKOLWsaEx"
      },
      "outputs": [],
      "source": [
        "#puzzles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXE6E5yM0Xv8"
      },
      "outputs": [],
      "source": [
        "#Spit out the questions and answers\n",
        "puzzlesQ = puzzles.question.copy()\n",
        "puzzlesA = puzzles.answer.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAvagLitgGQl"
      },
      "source": [
        "# **Testing the Wikipedia plot summaries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t3W0anDw1t7",
        "outputId": "ce1d66f7-2039-4e3c-ab41-9c30cb3bac5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.25498734907782167"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Self-METEOR on the baseline test set of fictional content - only needs doing once\n",
        "\n",
        "Total_METEOR = 0\n",
        "\n",
        "for i in plots_reviews_test:\n",
        "\n",
        "  METEOR = 0\n",
        "  references = [word_tokenize(txt) for txt in plots_reviews_test if txt != i] #exclude hypothesis\n",
        "  hypothesis = word_tokenize(i)\n",
        "  METEOR = nltk.translate.meteor(references,hypothesis)\n",
        "  Total_METEOR += METEOR\n",
        "\n",
        "Total_METEOR / len (plots_reviews_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emy33V868xi-"
      },
      "source": [
        "# **Testing the base model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7TASe4UiOKY"
      },
      "outputs": [],
      "source": [
        "#Load the model and tokeniser\n",
        "device=\"cuda\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgKWH3DB86qj"
      },
      "source": [
        "**Testing the base model on plot summary generations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKGoAlAzjDG-"
      },
      "outputs": [],
      "source": [
        "# encode the context/prompt that the generations will be conditioned on\n",
        "input_ids = tokenizer.encode('Here is the plot summary to a new and original science fiction novel:', return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A326XLsrikBk"
      },
      "outputs": [],
      "source": [
        "# Generating plot summaries with the base model\n",
        "predictions_vanilla=[]\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    no_repeat_ngram_size=2,\n",
        "    do_sample=True,\n",
        "    max_length=768,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=5.0, # VARY TEMPERATURE BETWEEN 1.0-3.0-5.0\n",
        "    num_return_sequences=93 # same as the test set size\n",
        ")\n",
        "\n",
        "sample_outputs = tokenizer.batch_decode(sample_outputs, skip_special_tokens=True)\n",
        "predictions_vanilla.extend([sample.replace(\"<n>\", \"\\n\") for sample in sample_outputs])\n",
        "#for i, sample_output in enumerate(sample_outputs):\n",
        "#  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQK7tZZk2SZ9",
        "outputId": "63b304d9-8251-4291-cb36-8dd555155412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.38687235934633474"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Self-METEOR for the base model generations\n",
        "\n",
        "Total_METEOR = 0\n",
        "\n",
        "for i in predictions_vanilla:\n",
        "\n",
        "  METEOR = 0\n",
        "  references = [word_tokenize(txt) for txt in predictions_vanilla if txt != i] #exclude hypothesis\n",
        "  hypothesis = word_tokenize(i)\n",
        "  METEOR = nltk.translate.meteor(references,hypothesis)\n",
        "  Total_METEOR += METEOR\n",
        "\n",
        "Total_METEOR / len (predictions_vanilla)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "1aa61e3e49ab4812a1cc507fbe37b838",
            "08d2226899594d84a09af73e99127c7e",
            "a1225c184cbf446089a4606f29583e64",
            "9816e5c8c93b408f95cbc4797ff3d02b",
            "7db61809296d4cdd9abc605334f9b489",
            "51c49a11b3db4cf68338dc67b7463eaf",
            "dfd64a1c9fd7424dbbe62013d90e32f2",
            "7fc845e5acbd478da058108621d39f3b",
            "436bf5c3c4084e8ba16a37db1d3643b6",
            "1ca072d0599d4e5687e7a5c50ba6a0a4",
            "5809df15b7924afebb2b2f7dbdcef863"
          ]
        },
        "id": "rHMuWN5QGOXG",
        "outputId": "616b0c29-9154-44b9-eda9-37d1f12ce58f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa61e3e49ab4812a1cc507fbe37b838",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1': np.float64(0.295065845768083), 'rouge2': np.float64(0.027147901927995204), 'rougeL': np.float64(0.12080661847894841), 'rougeLsum': np.float64(0.1427134131497179)}\n"
          ]
        }
      ],
      "source": [
        "#ROUGE-L for the base model generations vs. the baseline fictional content test set\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "referencez = []\n",
        "for i in range(93):\n",
        "  current_refs = []\n",
        "  for j in range(93):\n",
        "    current_refs.append(plots_reviews_test.iloc[j])\n",
        "  referencez.append(current_refs)\n",
        "\n",
        "predictionz = predictions_vanilla[0:93]\n",
        "resultz = rouge.compute(predictions=predictionz, references=referencez)\n",
        "print(resultz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEXKa8p79AUg"
      },
      "source": [
        "**Testing the base model on brainteaser puzzles**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_6jdch51nl5"
      },
      "outputs": [],
      "source": [
        "#Generating 10 answers to the first 10 shuffled brainteaser puzzles\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "predictions_puzzles=[]\n",
        "for i in range(10):\n",
        "  input_ = tokenizer.batch_encode_plus(puzzlesQ[i:i+1], max_length=768, pad_to_max_length=True,truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "  input_ids = input_['input_ids']\n",
        "  input_mask = input_['attention_mask']\n",
        "  answers = model.generate(input_ids=input_ids.to(device),\n",
        "                         attention_mask=input_mask.to(device),\n",
        "                         no_repeat_ngram_size=2,\n",
        "                         do_sample=True,\n",
        "                         top_k=50,\n",
        "                         top_p=0.95,\n",
        "                         temperature=5.0, # VARY TEMPERATURE BETWEEN 1.0-5.0\n",
        "                         num_return_sequences=1,\n",
        "                         max_length=128,\n",
        "                          )\n",
        "  answers = tokenizer.batch_decode(answers, skip_special_tokens=True)\n",
        "  predictions_puzzles.extend([answer.replace(\"<n>\", \"\\n\") for answer in answers])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0rlxOJ8zuyv",
        "outputId": "88982986-a44c-46e7-d3fe-e98c385fccdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Both persons who were playing chess won. What caused this to happen? On the surface some things are just obvious. But if you believe this you understand why that isn\" — The Old Gods.\\nThis piece, presented within two paragraphs of this paragraph that will be in my other column that contains another \"my thought process:\" my way: How this article was picked would shape your day life through your journey out west where your game design would be the most \"easy for\" while playing for The Church at St. Peter Academy was something I was prouder: my childhood dreams, to take over Saint Sperand at the hands, but',\n",
              " \"A chopper had ten pigeons inside and threw all of them out to die. However, there were some tall trees that could've survived them. How many survived? Eight are missing in three hours by far as their limbs don. Now look on high-scatter...\\n\\n\\nSo one would not feel more afraid at hearing your mother was alive until when their head hit it again a bunch in two of it but in your dreams when someone calls, that's for some unknown unknown reason. Anyway there she came as in dream when. So it is, so where did these birds survive then as compared back there. Was not like her\",\n",
              " 'You\\'re out on the sea and notice a boat full of people. You take a quick glance away and then back, but there is not a single person on the boat. Why? ~~~~~~~~= 2 The last step (or \\'turn left) from going on of cruise linings is for the oceanic wave at 1 km altitude to get over its height limit of ~3 and still to enter it in less dangerous waves due close ocean circulation of over 3 times an inch [2°, 45°). These surf balls only break because of slow erosion rates over longer passages by other side tides.\" So says Michael Pachov to Al',\n",
              " 'Mrs. Adams tells her neighbor that her son turns 16 today and that next birthday he\\'ll be 20. How can that be? My parents still take their kids away today too.\" What should your stepnolder tell everyone now this Christmas while I live down this side walk along Grand Lake Rd..where, according this tree I found that we\\'re already seeing new kids today . In doing just that your own self becomes like her uncle with love...\\n...he goes about explaining things you and he can read right for about 2 days because our grandchild and uncle do live at 10 pm on Wed when that gets in effect (probably due from',\n",
              " \"There is a young woman in her room thinking about her dreams. There is also another dancer in the room that is dancing in her best dress. However, only the young woman can see the dancer. How's that possible? Isn't dancing exciting?!\\n\",\n",
              " 'Four of Mrs. Jones\\' daughters exist. She has one brother for each of her daughters. Mrs. Jones, however, only has five kids. How is it even doable? And even if, for me, this can continue over long generations there seems less effort (I hope not this in a political race on this side of one line). Her kids come by only when you go and let each kid drive four weeks without fail,\" wrote The Specter earlier. \\'By some evidence I agree most teachers think there, including an interesting little film where (she appears to call this job one her \"most treasuring,\" given she has',\n",
              " \"Why can't a woman, who is now living in Canada, not be buried in the USA? And they said all we got in here during my last election period with you for you would also become free through the power brokers we already ran around! If that could just kill those Democrats here! As someone you talk down these terrible bastions who can throw this shit as well as these awful things you did over at Bernie Madoff & what not so I do want something about this cause as soon they throw what could at Hillary she comes! Can our daughters as an independent as a reason get this job again??\\n\\n:)(3 minutes of\",\n",
              " 'Lily stood on the edge of the 18th floor of the high-rise apartment complex. Overwhelmed with fatigue, she opened the balcony door and stepped out. It was a steep drop from the balcony to the pavement below. Amazingly, after stepping out, she was totally unscathed. Given that there was nothing to soften her landing or slow her descent, how could she have survived the step? If someone hadn) been climbing, had there something up and down in this small office on our backside doing an AMA before we got too high?\"\\nThere would presumably\\'ve only only been 9,450 of me (I hadn',\n",
              " 'A girl finds a door, opens it, after sometime her body is found dead how is that possible since nobody shot her? Even I won your hearts by knowing there to been three guys left when the body disappeared....The body still cannot open that door after being on this stage.\" What on god have humans even to take a page as they know who left where was at this date! Is an entire time the age for women!? A man comes around for this kind fuck but it turns it onto woman?!\\nA few men were killed trying their damned utmost in an ancient village then another group was sent flying by that kind wind blowing right like',\n",
              " \"Why is Christmas Day so chilly? To many of Israel's Orthodox Christian and religious residents that Christmas must provide no extra help on Jewish homes while allowing Christmas lights be turned during synagogue hours and at every religious event -- a tradition shared during Christian mass every century from 1451 (Moral laws define time from Adam 2; 1 Rom . 1 of 13; Ep 13 in 12-22 2 AD, in Acts xlvxi vxxvxi or Ep 2 Acts .1 ) and Jewish celebration each January during Hebrew service periods? Are Orthodox, Christians Jewish believers who simply wish no special encouragement at their wedding-party meetings over such things that in\"]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_puzzles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FSJ5e2GYMxT"
      },
      "source": [
        "# **Fine-tuning of GPT2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkQVIWT-WBUj"
      },
      "outputs": [],
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\", pad_to_max_length=True, return_tensors='pt')\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxcDhTqvyFdZ"
      },
      "outputs": [],
      "source": [
        "#use training data\n",
        "dataset = GPT2Dataset(plots_reviews_train, tokenizer, max_length=768)\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for dataset\n",
        "# Take data in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxB1DqnYgj8",
        "outputId": "e1798237-7b4f-44cd-a255-f008f5476313"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "configuration.pad_token_id = tokenizer.eos_token_id\n",
        "#configuration.loss_type = ForCausalLMLoss\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration).to(device)\n",
        "\n",
        "# this step is necessary because of the added tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm5ZL5t8ZSJp"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "\n",
        "epochs = 5 # change depending on how fitted to the fictional content want the fine-tuned generations to be\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=epsilon)\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVWJaThIbhq0"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBy4RsaCzLoh",
        "outputId": "53fbfe1c-317a-4932-8d73-2bf1915e20c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 3.03\n",
            "  Training epoch took: 0:01:17\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.07\n",
            "  Training epoch took: 0:01:17\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.83\n",
            "  Training epoch took: 0:01:17\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.62\n",
            "  Training epoch took: 0:01:17\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.46\n",
            "  Training epoch took: 0:01:17\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:06:24 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "#Training\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels,\n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JibiaZYedakP"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF8HH5odb7xw",
        "outputId": "c0b1748c-602d-490c-a2eb-480c47488638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257,  3423,   318,   262,  7110, 10638,   284,   257,   649,   290,\n",
            "          2656,  3783, 10165,  5337,    25]], device='cuda:0')\n",
            "0:  Here is the plot summary to a new and original science fiction novel: a spacecraft of immense suor and thrust. It has just begun flyby and reached our moon and far-half of space in order to explore what were earlier described after observations left by the Space Mariner. Within it are millions of tiny, humanoid spacecraft sent in small teams with no need to maintain regular links as people evolved slowly by late. Called the Pathfinder Mission Project - named for astronomer Edgar Rice Smith who was the subject of much lore (and parody at parts, with the exception, probably written Shakespeare, that a portion came down upon entry after publication). During construction and test phases nearly everyone undergoes regular physical changes - the most experienced among them those dealing directly with basic skin and basic tentacle bodily functions - most are mildly deform but functional nonetheless. Subject: Pathfinder Project Pathfinder goal Numbering forward 10 Years Aboard: Sun of Neptune Explorer Dimensions 1000 Light Drags and Bait: 2.50 Inseaman(s)/Crew 12 Speedboat Dimensions 600 Flight L: 22 Mars Hill: Landing Zone Mars Colonists Acknowleditive Comments In The Line By Alexander Gunn James Dellar discovered after traveling over 1 and 9 years in outer binary and nonlinearly interstellar space by Paul Westerwil that another world on other names was discovered, then abandoned due significantly weaker gravity constraints that applied during construction for the purpose of determining the \"first world to ever explore beyond Earth, of what will become known\". The lander which Pathfinder landed, or whatever is now planned after it reaches Saturn(orbiting Luna next Earth bound). It planned another colony for several decades so as to minimize longitude anomalies. That said in 2042 Venus orbit would join two proposed colony on potentially designated Photaxis (lower Moon trajectory), leaving 3 possible destination worlds; potentially Mars along. However on 2075 Mars would still orbit rather awkwardly as this planet(labeled as an M69 \"bomb\", in actuality part 30 miles away from Earth where an equivalent blast must be struck by 2077 gravity, plus volcanoes) with geologic activity at 3-,4&nbsp); higher altitude missions with potentially 2072 Mars-type bomb or phasing for more extreme storms, tsunams will need extensive protection prior to launching the initial stage rocket - either by dropping a single object upon a target at ground, but long term underground caves where only about two years is needed and potentially the majority \"bogey cases\" where shallow rock layers trap (which would be in place prior not knowing who launched its payload. When the landers receive launch codes, abbreviating numbers indicated. Near End Orbit The Orion MSB launched a mission shortly end 935 before the actual Mars mission carrying David Atal, as previously indicated: After at its very beginning moments out near End-World in 2007 at the close of mission Earth initiated \"magnanimous consent\". This resulted in at least partial communication to Ares Space Operations team via various secret message reels passed via Mir, the orbiting preurage relay spacecraft with a persistent magnetic field stretching far all the time. David immediately receives multiple \"signets\": one (later confirmed 30th sent by Mike Tyson (as sent off for at End of World proofreading duties)), from his handler Mike Ngoe back in Theology. In return he is promised: his five million translation grants the Martian Name (\"Name Two In Sight On Earth\") via Eqr 907 . During Venus/37'Nasa operations Jason Sharp undertook the unusual mission in honor of Yuri Korin and with all present was instrumental to discovering yet another promising new Phony/Claurian colony at near-High and intermediate orbits using EQ25 land erssify (derived approximately 30 times since Kos 17/UL 22. At high echelons in interstellar damp, Earth\n",
            "\n",
            "\n",
            "1:  Here is the plot summary to a new and original science fiction novel: (a few details omitted), first written to promote industrializing technology&mdashes&nbsp;\"High Aqassin Aerospace&ls;\" of 2034” By Eric A. Strayler & Richard Branson May 2005 ISBN 1-275248299-0 Chapter Summary September 1997: International Year :Yves Rochenfort International, Stuttent (short description based on 1977 events that the book will appear in on pg 130) :Michael Menezes Mar 1798 – 1974, the Bahamas, Cayledrode (cêmerisation de espanyole en buen fa—úvet plenio est hâuda)—(as originally mentioned by Fab Truss as originating material during Fantastic Aéroplay—[Perruss's father (whose surname appears below)|Eskimo-], plus a brief interjected speech and short biographical epilogue which include two lines as text – which end with Peter Rocson holding \"his gun over my cheek.\" It is mostly used as setting away references but also used to cover the later stage career which Yves had followed such-named (Ivan), Roger-Paul (the first man introduced as first spotted by Steve Chapman). May 4, 1978, involves a large number of press issues such a scandal at the Stadio Mar 25 ´ conference organised at YFest, media intrigue brought about concerning the transfer for membership by Aerion, a prestigious biosphere university&ndash;[res judice&l;to which Aerions licence), industrial instability at X-Force by Jean-Claude de Joms and reports of human-driven environmental destruction occurring on Ulla Verida Mountain and by periodic land and air frictions on Mount Heliabahn (mainly hydro) throughout the Caribbean which extend to Cape Verde. At length, Rochemfort confirms Mar 19 and relates that in 1983 the country became landlocked due the absence of communication satellite communication when most satellite frequencies died as people in Jamaica did. A major source of communications satellites and/or news of a potential nuclear bomb during that nuclear attack is broadcast only through newswire taps from the ground. As such any attempt has been delayed by years, resulting to massive, aerial sightings, low, windblown trees which were then removed&ncode\n",
            "’s surface/subso, so called by their ”freed-in— from under their feet and, through to later airtight enclaves the trees continue their march towards civilization as the indigenous “humanity breathens back more air &mdash;\" and the coastal vernings — all native herbs and flower shades which remain untouched, but which cannot change shape because light must enter such close range such that half fall within 250 feet while growing beyond the cones at night and much greater distance into tall vegetation under heavy dowsing — begin the \"genocide\". Also spring flowers sprouting as winter begins (and seed has grown on tins of tangerines and aprons under sunning; these later become seedstock—and are referred partly ‾ to Mommalita and then ‡Yq'quilaya.) by Mic. Mic tells him they see, first through looking like stereotypical bearded men posing for tabloid cameras as they shower the sun, at first initially sceptical among readers of historical periodicals: a young reporter with casual tastes decides it would also benefit his new-found craft – assuming for illustration lessons not the necessity for new equipment since soil quality suffers with use-worn accessories such as tiebreakers, long underwear on both back and high and strong wooden paddle beds; Mic adds: * After discussing ways of bringing food back which, he believes (based on events at Fantastic As\n",
            "\n",
            "\n",
            "2:  Here is the plot summary to a new and original science fiction novel: \"...A civilization overrun to almost its maximum insanity can almost frighten an entire army!\" —Michael Williams‟In the wake of a disaster as predicted by extraterrestrials centuries previously and chronicled elsewhere \"Tycho's Tooth\" series \"starfighters: extraterladivers in orbit, never forgetting, and being aware even of times that previously did sometimes seem strange again\" *Ty Cho (2004, Empire Now) First appearance of Sylar Ty in an omniscient miniseries (War on Terror in Air and Two Dimensions ) at The Space Cadet Academy in December 2005 alongside character interviews in Star Trek VI ( The Ultimate Aircarrier ) while appearing before members in a Space opera by the British band Spitwerk. These are followed several decades apart now and the two continue as co-productors for \"Starsider\" magazine’s adult section (see Star-Teams below for separate editions.) *Lincoln Aching Heart is about a newly commissioned arctologist investigating various childhood insults that character actress Ann Curry has encountered to make her become a strong Doctor of Laws advocate against alien interference (often by \"greons,\" female voice cheques are regularly kept close-farms for these, although their male hosts get progressively warmer hours out of other people's business if they don't take extra oxygen to heal). When one girl‏ names someone after Hermann Fyfe of Heinlein works within reach where Arcult G. Knoel of House and Prison \"offers,\" rather ironically though ostensibly written for a mature viewer she introduces the latter product with considerable scientific plausibility, even to skeptics (a comment about relativity permeation upon reading this magazine that seems typical of Kleen, Wilde, Strauss Reviews from 1960 suggests a double blind experiment would easily be performed. Yet what can both of our spies uncover as far as plausitie \"reveal possible fiction\"? This one seems certain from what has led both Michael  Lykander with a long shelf, the publication of fifteen previously discovered, preclusive non scientific tales for children of stellar civilization” of varying geometrical type published since around 3050 and available on the Disc; in spite his heavy industry involvement it has always come just shy of official entry by radio and television news reports from major U.S. hosting facilities since 1997, including the prestigious Acadiere Gondor Hotel:\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Generating sample plot summaries from the fine-tuned model for the appendix of the report\n",
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|> Here is the plot summary to a new and original science fiction novel:\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated,\n",
        "                                no_repeat_ngram_size=2,\n",
        "                                do_sample=True,\n",
        "                                top_k=50,\n",
        "                                max_length = 768,\n",
        "                                top_p=0.95,\n",
        "                                temperature=3.0,\n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmGrHCsAtIiX"
      },
      "outputs": [],
      "source": [
        "#Generating the 93 sample plot summaries with the fine-tuned model to be used for testing\n",
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|> Here is the plot summary to a new and original science fiction novel:\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "predictions_finetune=[]\n",
        "\n",
        "sample_outputz = model.generate(\n",
        "    generated,\n",
        "    no_repeat_ngram_size=2,\n",
        "    do_sample=True,\n",
        "    max_length=768,\n",
        "    top_k=25, # ONCE TEMP SET TO 3.0 VARY K FROM 25-50-100\n",
        "    top_p=0.95,\n",
        "    temperature=3.0, # FIRST VARY TEMPERATURE BETWEEN 1.0-1.5-5.0, THEN SET TO 3.0 AND VARY TOP K\n",
        "    num_return_sequences=93\n",
        ")\n",
        "\n",
        "sample_outputz = tokenizer.batch_decode(sample_outputz, skip_special_tokens=True)\n",
        "predictions_finetune.extend([sample.replace(\"<n>\", \"\\n\") for sample in sample_outputz])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_86-HsjjK5x",
        "outputId": "2be2147a-da09-4c9c-ee49-de7c353428ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34966028915953745"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#Self-METEOR for the generated examples post finetune\n",
        "\n",
        "Total_METEOR = 0\n",
        "\n",
        "for i in predictions_finetune:\n",
        "\n",
        "  METEOR = 0\n",
        "  references = [word_tokenize(txt) for txt in predictions_finetune if txt != i] #exclude hypothesis\n",
        "  hypothesis = word_tokenize(i)\n",
        "  METEOR = nltk.translate.meteor(references,hypothesis)\n",
        "  Total_METEOR += METEOR\n",
        "\n",
        "Total_METEOR / len (predictions_finetune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWr5tcM-QtfW",
        "outputId": "8304ade2-e870-4626-a38d-1f18973058f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:evaluate.loading:Using the latest cached version of the module from /root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--rouge/b01e0accf3bd6dd24839b769a5fda24e14995071570870922c71970b3a6ed886 (last modified on Tue Apr 15 09:02:34 2025) since it couldn't be found locally at evaluate-metric--rouge, or remotely on the Hugging Face Hub.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': np.float64(0.2938029215334478), 'rouge2': np.float64(0.03258592858053651), 'rougeL': np.float64(0.13257126328247548), 'rougeLsum': np.float64(0.13281632944853056)}\n"
          ]
        }
      ],
      "source": [
        "#ROUGE-L for the fine-tuned generations vs. the baseline fictional content test set\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "references = []\n",
        "for i in range(93):\n",
        "  current_refs = []\n",
        "  for j in range(93):\n",
        "    current_refs.append(plots_reviews_test.iloc[j])\n",
        "  references.append(current_refs)\n",
        "\n",
        "predictions = predictions_finetune[0:93]\n",
        "results = rouge.compute(predictions=predictions, references=references)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO3IZR1P2wqt",
        "outputId": "b9e6a8ba-ac9c-4416-f348-4324ce49d355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "#Answering brainteaser puzzles with the fine-tuned model\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "predictions_puzzlez=[]\n",
        "for i in range(10):\n",
        "  input_ = tokenizer.batch_encode_plus(puzzlesQ[i:i+1], max_length=768, pad_to_max_length=True,truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "  input_ids = input_['input_ids']\n",
        "  input_mask = input_['attention_mask']\n",
        "  answerz = model.generate(input_ids=input_ids.to(device),\n",
        "                         attention_mask=input_mask.to(device),\n",
        "                         no_repeat_ngram_size=2,\n",
        "                         do_sample=True,\n",
        "                         top_k=25, # ONCE TEMP SET TO 3.0 VARY K FROM 25-50-100\n",
        "                         top_p=0.95,\n",
        "                         temperature=3.0, # FIRST VARY TEMPERATURE BETWEEN 1.0-5.0, THEN SET TO 3.0 AND VARY TOP K\n",
        "                         num_return_sequences=1,\n",
        "                         max_length=128\n",
        "                         )\n",
        "  answerz = tokenizer.batch_decode(answerz, skip_special_tokens=True)\n",
        "  predictions_puzzlez.extend([answer.replace(\"<n>\", \"\\n\") for answer in answerz])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZcSYTibEJWD",
        "outputId": "349cb6c9-f3e1-40f7-b0c6-fe0a09c6e766"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Both persons who were playing chess won. What caused this to happen? Is the world to last in chess? The book begins with an opening description by John Clayton on one chess master forum which features one user's summary of chess winning matches, before moving up to his question, comparing wins (won, lost and played against others for answers by a newcomer), draws of the pieces, plays, strategy, and the rules of one system as described in that book itself, following those in the Discourses and chess book Viva Lo D'a (among other books like This Game Of Whorl After The Skies Or One Thousand Voyages,\",\n",
              " 'A chopper had ten pigeons inside and threw all of them out to die. However, there were some tall trees that could\\'ve survived them. How many survived? Well one was a long bird that died after giving birth in his forest one Sunday, then rose and became a lady-bird in her family\\'s yard. Then three died on coming through gates one and two. One went with another in the bird care system and they were all adopted by Mr. Cook but none came home in all ten cases—except an enormous white one named Prillimmed (not the name is pronounced \"Pretty Little Pied Piper\"), also hatched',\n",
              " \"You're out on the sea and notice a boat full of people. You take a quick glance away and then back, but there is not a single person on the boat. Why? ۙArabistan doesn't know anything but for some unexplained reason—for example a Persian skyle—you see three people with what appears to be silver scythe scions clutching something, clearly an Indian Shaman—which is a very unusual turn. Then something in the distance turns and all 3 are standing before one large stone circle carved for 'three', and 'a fourth'. You notice an enormous crocodarch arch in that 'pool', so\",\n",
              " \"Mrs. Adams tells her neighbor that her son turns 16 today and that next birthday he'll be 20. How can that be? This will change nothing for Harry Potter and it can't be her baby after all... He knows, since he used to watch TV with Aunt Marge at the zoo. Aunt is very upset by this idea because when Harry is a new boy he is no longer recognised as like Auntie but the boy always knows who his Aunties is! She hates this. Her father tells Aunt that this has not stopped the growth of Harry's personality as all children grow to astonishing speed in their last ten wishes as their Aunt\",\n",
              " \"There is a young woman in her room thinking about her dreams. There is also another dancer in the room that is dancing in her best dress. However, only the young woman can see the dancer. How's that possible? The older her friend, or the girl that was the best friend (if the older women never knew the woman), she continues with one idea which is that her sister was going through some difficult stages, which could result naturally from love. But now all those words and deeds become part of the same secret—and with it the identity not only of what was said in school; the truth of who is to say them\",\n",
              " \"Four of Mrs. Jones' daughters exist. She has one brother for each of her daughters. Mrs. Jones, however, only has five kids. How is it even doable? Her family must somehow devise the appropriate way to raise four very intelligent children. Only the clever will do. And when Mrs Narrow becomes Prime minister only five smart and powerful men -- Jack Spratt-Smith and James O'Donohoe --- must stand up and do just that in time - not too quickly! That task must include dealing with Jack Sewlen's widow, Miss Parnell, the incompetent governess Nitasha Brown - the most formidable\",\n",
              " \"Why can't a woman, who is now living in Canada, not be buried in the USA? Wouldn't it be easier in America to keep track of where Anita is buried now and her lover Paul Joseph Smith is, and find something he has read recently while driving down the Ohio-Kentucky line? Well... she seems to fit neatly, exactly as it appears, inside Mary McLeod’s home: neatly placed with plenty and a tomboy like girlfriend, Peggy McIntire, in its elegant and quintessential British setting at her parents' former mansion near Toronto where, although apparently, Anita lived. In addition to her tomb,\",\n",
              " \"Lily stood on the edge of the 18th floor of the high-rise apartment complex. Overwhelmed with fatigue, she opened the balcony door and stepped out. It was a steep drop from the balcony to the pavement below. Amazingly, after stepping out, she was totally unscathed. Given that there was nothing to soften her landing or slow her descent, how could she have survived the step? After two months she began walking again and walking a couple inches through glass. But in spite of all the exerting work her foot hurt completely and she didn't even feel what happened to her... It hadn't snowed all day\",\n",
              " 'A girl finds a door, opens it, after sometime her body is found dead how is that possible since nobody shot her? But how will that ever be determined as a homicide or murder/apartheid, or a terrorist group, be trying to reach in from England with this key piece of incriminating tape, a phone video from a remote location, and hundreds of boxes full of evidence? Until that moment her life seems completely lost without you noticing.....or she might just cry in pain as if nothing were as strange from within. Could it still be all a nightmare made just an excuse by the ruthless tyrants of North Eastern? You',\n",
              " 'Why is Christmas Day so chilly? Scientists have warned their forebears of this, yet it proves to be an unseasonably fey, cold blizzard and cold snap have driven the country into a series’ storms, snowfall far faster than scientists initially had believed... The blustering temers in northern Tasmania have forced travel hundreds faster; a new expedition from the Royal Nusander Institute is moving swiftly north of Hereford, in the southern part of Western Australia to locate a missing family, and bring them to an uninhabited area called Thunder Glen, described in descriptions as \"cold but thick,\" and \"immapped']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "predictions_puzzlez"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyMY99RcZnG1zrYbXRsjJn4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08d2226899594d84a09af73e99127c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c49a11b3db4cf68338dc67b7463eaf",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd64a1c9fd7424dbbe62013d90e32f2",
            "value": "Downloading builder script: 100%"
          }
        },
        "1aa61e3e49ab4812a1cc507fbe37b838": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08d2226899594d84a09af73e99127c7e",
              "IPY_MODEL_a1225c184cbf446089a4606f29583e64",
              "IPY_MODEL_9816e5c8c93b408f95cbc4797ff3d02b"
            ],
            "layout": "IPY_MODEL_7db61809296d4cdd9abc605334f9b489"
          }
        },
        "1ca072d0599d4e5687e7a5c50ba6a0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436bf5c3c4084e8ba16a37db1d3643b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51c49a11b3db4cf68338dc67b7463eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5809df15b7924afebb2b2f7dbdcef863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7db61809296d4cdd9abc605334f9b489": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc845e5acbd478da058108621d39f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9816e5c8c93b408f95cbc4797ff3d02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ca072d0599d4e5687e7a5c50ba6a0a4",
            "placeholder": "​",
            "style": "IPY_MODEL_5809df15b7924afebb2b2f7dbdcef863",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 704kB/s]"
          }
        },
        "a1225c184cbf446089a4606f29583e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc845e5acbd478da058108621d39f3b",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_436bf5c3c4084e8ba16a37db1d3643b6",
            "value": 6270
          }
        },
        "dfd64a1c9fd7424dbbe62013d90e32f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}